\documentclass[12pt,twoside]{article}

\usepackage{jmlda}
\usepackage{datetime}
\usepackage{multicol}
\graphicspath{{./pics/}}

\pgfplotsset{compat=1.12}

\bibliographystyle{gost780u}
\graphicspath{{./pics/}}

\newcommand*{\fullref}[2]{\hyperref[{#1}]{\nameref*{#1} #2}}

\begin{document}

%\NOREVIEWERNOTES
\title
    [Классификация временных рядов]
    {Классификация временных рядов в пространстве параметров порождающих моделей}
\author
    {Карасиков~М.\,Е.}
\email
    {karasikov@phystech.edu}
\organization
    {Московский физико-технический институт}
\thanks
    {Научный руководитель: Стрижов~В.\,В.}
\abstract
    {Работа посвящена задаче многоклассовой признаковой классификации временных рядов.
    Признаковая классификация временных рядов заключается в сопоставлении каждому временному ряду его краткого признакового описания, позволяющему решать задачу классификации в пространстве признаков.
    В работе исследуются методы построения пространства признаков временных рядов.
    При этом временной ряд рассматривается как последовательность сегментов, аппроксимируемых некоторой параметрической моделью, параметры которой используются в качестве их признаковых описаний.
    Построенное так признаковое описание сегмента временного ряда наследует от модели аппроксимации такие полезные свойства, как инвариантность относительно сдвига.
    Для решения задачи классификации в качестве признаковых описаний временных рядов предлагается использовать распределения параметров аппроксимирующих сегменты моделей, что обобщает базовые методы, использующие непосредственно сами параметры аппроксимирующих моделей.
    Проведен ряд вычислительных экспериментов на реальных данных, показавших высокое качество решения задачи многоклассовой классификации.
    Эксперименты показали превосходство предлагаемого метода над базовым и многими распространенными методами классификации временных рядов на всех рассмотренных наборах данных.

		\parindent=1cm \textbf{Последние изменения}: \currenttime, \today

		\bigskip
		\textbf{Ключевые слова}: \emph {временные ряды, многоклассовая классификация, сегментация временных рядов, гиперпараметры аппроксимирующей модели, модель авторегрессии, дискретное преобразование Фурье, дискретное вейвлет"=преобразование}.}
\titleEng
    {Time series feature"~based classification}
\authorEng
    {Karasikov~M.\,E.}
\organizationEng
    {Moscow Institute of Physics and Technology}
% \abstractEng
    % {We consider time series feature"~based classification problem.
    % Classification algorithm using model parameters distribution is proposed.
    % Empirical experiments on real data are conducted.

    % \bigskip
    % \textbf{Keywords}: \emph{time"~series, feature-based classification}.}

\maketitle
%\linenumbers

\section{Введение}
\label{sec:introduction}
Временным рядом~$x$ будем называть конечную упорядоченную последовательность чисел:
\[
x = [x^{(1)}, \dots, x^{(t)}].
\]
Временные ряды являются объектом исследования в таких задачах анализа данных, как
  прогнозирование~\cite{weigend1994time, tsay2005analysis},
  обнаружение аномалий~\cite{weiss2004mining},
  сегментация~\cite{geurts2005segment},
  кластеризация~\cite{WarrenLiao20051857, zolhavarieh2014review}
  и классификация~\cite{wang2014human, Wei:2006:STS:1150402.1150498, geurts2005segment}.
Обзор по задачам и методам анализа временных рядов дается в~\cite{Esling:2012:TDM:2379776.2379788, fu2011review}.
Последние годы связаны с ростом интереса к данной области, проявляющимся в непрекращающимся предложении новых методов анализа временных рядов~---
  метрик~\cite{Ding:2008:QMT:1454159.1454226, salvador2007toward, marteau2009time},
  алгоритмов сегментации~\cite{vasko2002estimating, Esling:2012:TDM:2379776.2379788, fu2011review},
  кластеризации~\cite{frohwirth2008model, Corduas20081860, Esling:2012:TDM:2379776.2379788, fu2011review}
  и других.

В данной работе рассматривается задача классификации временных рядов, возникающая во многих приложениях
  (медицинская диагностика по ЭКГ~\cite{basil2014automatic} и ЭЭГ~\cite{marcel2007person, alomari2013automated},
  классификация типов физической активности по данным с акселерометра~\cite{6889585, Kwapisz:2011:ARU:1964897.1964918},
  верификация динамических подписей~\cite{gruber2006signature}~и~т.\,д.).

Формально задача классификации в общем виде может быть поставлена следующим образом.
Пусть~$X$~--- множество описаний объектов произвольной природы,
$Y$~--- конечное множество меток классов.
Предполагается существование целевой функции~--- отображения~$y:\;X\to Y$,
значения которого известны только на~объектах обучающей выборки
\[
    \mathfrak{D} = \left\{(x_1,y_1),\dots,(x_m,y_m)\right\} \subset X\times Y.
\]
Требуется построить алгоритм~$a:\;X\to Y$~--- отображение,
приближающее целевую функцию~$y$ на~множестве~$X$.
При $|Y|>2$ задачу классификации будем называть многоклассовой.
Задачей классификации временных рядов будем называть задачу классификации, в которой объектами классификации являются временные ряды.

Задание метрики~--- функции расстояния~\cite{Ding:2008:QMT:1454159.1454226, salvador2007toward, marteau2009time} на парах временных рядов позволяет применять метрические методы классификации.
При удачном выборе метрики дальнейшая классификация может происходить при помощи простейших метрических алгоритмов классификации, например, методом ближайшего соседа~\cite{jeong2011weighted}.
Данный подход к решению задачи классификации временных рядов чрезвычайно распространен в силу того, что позволяет свести исходную задачу классификации временных рядов к задаче выбора метрики, а также позволяет использовать graph"~based методы частичного обучения~\cite{nguyen2011positive, marussy2013success}.

Другой подход к решению задачи классификации состоит в построении для каждого временного ряда его информативного признакового описания~$\mathbf{f}:\;X\to\mathbb{R}^n$, позволяющего строить точные классификаторы с хорошей обобщающей способностью.
Построение информативного пространства признаков исходных объектов множества~$X$, позволяющего добиться заданной точности классификации и значительно упрощающего последующий анализ, является важнейшим этапом решения задачи классификации.
Признаки могут задаваться экспертом.
Так в работе~\cite{Nanopoulos01feature-basedclassification} предлагается использовать в качестве признаков статистические функции (среднее, отклонения от среднего, коэффициенты эксцесса и др.).
Стоит заметить, что при таком подходе к построению пространства признаков часто удается добиться необходимого качества классификации путем выбора соответствующих конкретной задаче признаков (см. пример ~\cite{wiens2012patient}), а сам выбор признаков становится важной технической задачей.
Второй метод построения пространства признаков заключается в задании параметрической регрессионной или аппроксимирующей модели временного ряда.
Тогда в качестве признаков временных рядов будут выступать параметры настроенной модели.
В работе~\cite{morchen2003time} в качестве признаков предлагается использовать коэффициенты дискретного преобразования Фурье (DFT), в~\cite{morchen2003time, zhang2004non}~--- дискретного вейвлет"=преобразования (DWT), а в~\cite{Corduas20081860, kini2013large} модели авторегрессии.
В~\cite{kalliovirta2015gaussian} исследуются свойства смеси моделей авторегрессии.
Таким образом, при данном методе построения признаковых описаний возникает задача выбора аппроксимирующей модели временного ряда. 
Об исчерпывающих исследованиях этой задачи авторам неизвестно.

В работе исследуются методы классификации временных рядов, использующие в качестве их признаковых описаний параметры аппроксимирующих моделей.
Приводится сравнение моделей аппроксимации.
Как из всякой последовательности, из временного ряда могут извлекаться его подпоследовательности, для которых может строиться признаковое описания так же, как и для исходных временных рядов.
Использование подпоследовательностей (фрагментов) позволяет обобщить алгоритмы классификации. Так в работе~\cite{geurts2005segment} предлагается алгоритм классификации временных рядов методом голосования их случайных сегментов (непрерывных подпоследовательностей со случайным начальным элементом).
В нашей работе предлагается алгоритм классификации временных рядов в пространстве распределений признаков их сегментов, который сравнивается с родственным ему алгоритмом голосования сегментов~\cite{geurts2005segment}.
В разделе~\fullref{sec:computational_experiment}{Вычислительный эксперимент} приводятся эксперименты на реальных данных, показывающие высокое качество и общность предлагаемого алгоритма в сочетании с методом признаковых описаний временных рядов параметрами аппроксимирующих их моделей.

\bigskip
\section{Постановка задачи}
\label{sec:problem_statement}
Поставим задачу в общем виде.

Пусть $(X,d)$~--- метрическое пространство временных рядов, $Y$~--- множество меток классов.
Дано конечное множество временных рядов~$X^\ell=\{x_1,\dots,x_\ell\}\subset X$ и обучающая выборка~$\mathfrak{D}\subset X^\ell\times Y$.

 % состоящих из сегментов~--- элементов некоторого метрического пространства~$(S,d)$:
% \[
% x_i=(s^{(1)}_i,\dots,s^{(p)}_i)\in S^p,\quad i=1,\dots,\ell;
% \]

Заданы алгоритм выделения фрагментов временного ряда
\begin{equation}
\label{eq:fragmenting}
s:\;x\mapsto (s^{(1)},\dots,s^{(p)})\in X^p,\text{ где } p=p(x),
\end{equation}
и параметрическая регрессионная модель фрагментов временного ряда
\begin{equation}
\label{eq:regression}
g:\;\mathbb{R}^n\times X\to X.
\end{equation}
Каждому фрагменту~$s^{(k)}$ временного ряда~$x$ поставим в соответствие его вектор признаков
\begin{equation}
\label{eq:feature_solution}
\vec{f}(s^{(k)}) =
\argmin_{\vec{w}\in \mathbb{R}^n} d\left(g(\vec{w},s^{(k)}), s^{(k)}\right).
\end{equation}
Таким образом, каждому временному ряду~$x$ соответствует набор векторов признаков
\[
\mathbf{f}=\left(\vec{f}(s^{(1)}),\dots,\vec{f}(s^{(p)})\right)
\]
его фрагментов.

% Пусть~$F(\vec{x})$~--- функция распределения, восстановленная по выборке~$F_i$.

Задано некоторое семейство алгоритмов классификации
\begin{equation}
\label{eq:classifiers}
A=\{a:\;\mathbf{f}\mapsto y\in Y\}
\end{equation}
и функция потерь
\[
\mathscr{L}:\;X\times Y\to \mathbb{R}.
\]

Найти алгоритм классификации~$a^*\in A,$ доставляющий минимум функционалу качества~$Q(a, \mathfrak{D})\in \mathbb{R},\quad a\in A:$
\begin{align*}
a^*
& = \argmin_{a\in A}Q(a,\mathfrak{D})=\\
& = \argmin_{a\in A}\frac{1}{|\mathfrak{D}|}\sum\limits_{(x_i,y_i)\in\mathfrak{D}}      \mathscr{L}\left(a\left(\mathbf{f}_i\right),y_i\right).
\end{align*}

\bigskip
\section{Выделение фрагментов}
\label{sec:fragmenting}
% В частном случае, когда временной ряд является квазипериодическим, существует возможность выделения в нем характерных сегментов~--- периодов, то есть возможность представления каждого временного ряда~$x = [x^{(1)}, \dots, x^{(t)}]$ последовательностью в определенном смысле похожих его сегментов~$s^{(1)},\dots,s^{(p)}:$
% \[
% s^{(1)}=[x^{(1)}, \dots, x^{(t_1)}],
% \ \dots\ ,
% s^{(k)}=[x^{(t_{k-1} + 1)}, \dots, x^{(t_k)}],
% \ \dots\ ,
% s^{(p)}=[x^{(t_{p-1} + 1)},\dots,x^{(t)}].
% \]
% В таком случае будем писать
% \begin{equation}
% \label{eq:periodic}
% x=(s^{(1)}, \dots, s^{(p)}).
% \end{equation}
% Для выделения периодов могут быть использованы, например, алгоритмы~\cite{geurts2005segment, nunthanid2012parameter, shatkay1996approximate, li1998malm, vasko2002estimating}.


В данном разделе рассматривается проблема выделения фрагментов из временного ряда~(см.~\ref{eq:fragmenting}).
Фрагментом временного ряда~$x=[x^{(1)},\dots,x^{(t)}]$ будем называть любую его подпоследовательность~$s=[x^{(i_1)},\dots,x^{(i_k)}],$ где $1\leq i_1\leq\dots\leq i_k\leq t$.
Например, сам временной ряд~$x$ является своим фрагментом.
То есть в качестве алгоритма выделения временного ряда можно взять
\begin{equation}
\label{eq:equal_fragmenting}
s:\;x\mapsto x\in X.
\end{equation}

Пусть теперь временной ряд является квазипериодическим.
То есть справедливо представление~\ref{eq:periodic}.
Тогда возьмем в качестве фрагментов ряда его сегменты
\begin{equation}
\label{eq:segment_fragmenting}
s:\;x\mapsto (s^{(1)},\dots,s^{(p)})\in X^p.
\end{equation}
Сегментация временных рядов может проводиться согласно алгоритмам~\cite{geurts2005segment, nunthanid2012parameter, shatkay1996approximate, li1998malm, vasko2002estimating}.
Общие требования к процедуре выделения фрагментов из временных рядов сформулированы в разделе~\ref{sec:classification}.

\bigskip
\section{Регрессионная модель временного ряда}
\label{sec:regression_model}
В качестве признаков фрагментов временного ряда используется вектор параметров аппроксимирующей модели~\ref{eq:regression}.
Рассмотрим несколько простых примеров.
\begin{itemize}
\item \textbf{Простая линейная регрессия}.
Пусть задан многокомпонентный временной ряд~(например, время и 3 пространственные координаты):
\[
x = [\vec{x}^{(1)}, \dots, \vec{x}^{(t)}],\quad
\text{где}\quad
\vec{x}^{(k)}=[z_0^{(k)},\dots,z_r^{(k)}]\T.
\]
Тогда нашей аппроксимирующей моделью, например, может быть модель линейной регрессии одной из компонент временного ряда на остальные компоненты:
\[
g(\vec{w},x)=[\hat{\vec{x}}^{(1)},\dots,\hat{\vec{x}}^{(t)}],\quad\text{где}\quad
\hat{\vec{x}}^{(k)}=[\hat{z}_0^{(k)},z_1^{(k)},\dots,z_r^{(k)}]\T,\ k=1,\dots,t,
\]
\[
\hat{\vec{z}}_0=
\begin{bmatrix}
\hat{z}_0^{(1)} \\
\vdots  \\
\hat{z}_0^{(t)}
\end{bmatrix}=
\begin{bmatrix}
\hat{z}_1^{(1)} & \dots & \hat{z}_r^{(1)} \\
\vdots         & \ddots & \vdots          \\
\hat{z}_1^{(t)} & \dots & \hat{z}_r^{(t)}
\end{bmatrix}
\begin{bmatrix}
w_1 \\
\vdots  \\
w_r
\end{bmatrix}.
\]

\item \textbf{Авторегрессионная модель AR($k$)}.
Задан временной ряд
\[
x = [x^{(1)},\dots,x^{(t)}],\quad x^{(k)}\in\mathbb{R}.
\]
Выберем в качестве модели порождения авторегрессионную модель порядка~$p$:
\begin{equation}
\label{eq:autoregressive_model}
g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
\hat{x}^{(k)}=w_0 + \sum\limits_{i=1}^{p} w_i x^{k-i},\ k=1,\dots,t.
\end{equation}

\item \textbf{Дискретное преобразование Фурье}.
Задан временной ряд
\[
x = [x^{(0)},\dots,x^{(t-1)}],\quad x^{(k)}\in\mathbb{R}.
\]
Очевидно, что задание признакового описания временного ряда коэффициентами Фурье эквивалентно заданию порождающей модели
\[
g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
\hat{x}^{(k)}=\frac{1}{t}\sum\limits_{j=0}^{t-1} w_j e^{\frac{2\pi i}{t}kj},\ k=0,\dots,t-1
\]
и евклидового расстояния в пространстве временных рядов.

% Запишем преобразование Фурье
% \[
% w_k = \sum\limits_{j=0}^{t-1} x^{(j)}e^{-\frac{2\pi i}{t}kj},\ k=0,\dots,t-1.
% \]
% и занулим все коэффициенты кроме первых~$p$:
% \[
% g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
% \hat{x}^{(k)}=w_0 + \sum\limits_{i=1}^{p} w_i x^{k-i},\ k=1,\dots,t.
% \]
\end{itemize}
Приведенные примеры демонстрируют большую общность построения пространства признаков при помощи модели типа~\ref{eq:regression} и решения оптимизационной задачи~\ref{eq:feature_solution}.
Вообще, легко видеть, что любая функция временного ряда~$\vec{f}:X\to \mathbb{R}^n$ может быть задана как решение оптимизационной задачи~\ref{eq:feature_solution} с соответствующей моделью~\ref{eq:regression} и функцией расстояния~$d$.

\bigskip
\section{Алгоритм классификации}
\label{sec:classification}
В данном разделе займемся задачей построения семейства алгоритмов~\ref{eq:classifiers}.
Пусть
\[
\mathbf{f}_i=\left(\vec{f}_i^{(1)},\dots,\vec{f}_i^{(p)}\right)
\]
--- полученное признаковое описание временного ряда~$x_i\in X^\ell$, где~$\vec{f}_i^{(k)}$~--- вектор признаков $k$"~го фрагмента этого ряда.
Признаковое описание~$\mathbf{f}_i$ можно рассматривать как реализацию выборки случайных величин
\[
\mathbf{F}_i=\left(\vec{F}_i^{(1)},\dots,\vec{F}_i^{(p)}\right).
\]
Примем гипотезу о простоте выборок~$\mathbf{F}_i,\ i=1,\dots,\ell.$
Данная гипотеза формулирует требования на метод фрагментации~\ref{eq:fragmenting}.
Тогда временной ряд естественно описывать распределением параметров порождающей модели его сегментов.
Пусть задана некоторая параметрическое семейство распределений~$\left\{\mathsf{P}_\theta\right\}_{\theta\in \Theta}$.
Тогда, получив оценку максимального правдоподобия
\[
\theta_i=\argmax_{\theta\in\Theta}L(\theta\,|\,\mathbf{f}_i),
\]
будем считать её признаковым описанием исходного временного ряда.
Таким образом, задача классификации временных рядов свелась к задаче классификации параметров распределений из семейства~$\left\{\mathsf{P}_\theta\right\}_{\theta\in \Theta}$.
При этом, имея априорное распределение параметра~$G(v)=\mathsf{P}\{\theta<v\}$, целесообразно использовать вместо оценки максимального правдоподобия апостериорное математическое ожидание параметра
\[
\theta_i=\mathsf{E}\left[\theta\,|\,\mathbf{f}_i\right].
\]

\bigskip
\section{Вычислительный эксперимент}
\label{sec:computational_experiment}

Вычислительный эксперимент проводился на данных для задачи классификации типов физической активности человека.

\subsection{Датасет WISDM~\cite{Kwapisz:2011:ARU:1964897.1964918}}
содержит показания акселерометра для $6$~видов человеческой активности:
\begin{multicols}{2}
\begin{enumerate}
  \item Jogging
  \item Walking
  \item Upstairs
  \item Downstairs
  \item Sitting
  \item Standing
\end{enumerate}
\end{multicols}

Необработанные временные ряды, представляющие из себя последовательность размеченных показаний акселерометра (по тройке чисел на каждый отсчет времени с интервалом в $50$ миллисекунд), были разбиты на временные ряды длиной по $200$~отсчетов~($10$~секунд).

\begin{table}[H]
  \begin{tabular}{|c||c|c|c|c|c|c|}
    \hline
    Классы & Jogging & Walking & Upstairs & Downstairs & Sitting & Standing\\ \hline
    Число объектов & $1624$ & $2087$ & $549$ & $438$ & $276$ & $231$\\ \hline
  \end{tabular}
  \caption{Распределение временных рядов по классам. Dataset:~WISDM.}
\label{tbl:manual_usc_had}
\end{table}

\subsubsection{Ручное выделение признаков}
\paragraph{Выбор признаков.}
\label{par:manual_feature_selection}
В первом эксперименте в качестве признаковых описаний временных рядов использовались их статистические функции.
Каждой компоненте временного ряда сопоставлялись $40$~чисел~--- её среднее, стандартное отклонение, средний модуль отклонения от среднего, гистограмма с $10$ областями равной ширины.
Полученные признаки для каждой компоненты объединялись и к ним добавлялся признак средней величины ускорения.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-One.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=8.5,\ \gamma=0.12$.

\paragraph{Результаты.}
Для оценки качества решения использовалась процедура скользящего контроля.
Исходная обучающая выборка~$\mathfrak{D}$ случайно разбивается $m$ раз на обучающую и контрольную~($\mathfrak{D}=\mathfrak{L_i}\sqcup\mathfrak{T_i}$). В качестве внешнего критерия качества метода обучения~$\mu$ бралось
\[
\frac{1}{m}\sum_{i=1}^{m}Q(\mu(\mathfrak{L_i}),\mathfrak{T_i}),
\]
где для средней точности (accuracy) классификации объектов класса~$c\in Y$
\begin{equation}
\label{eq:class_quality}
Q_c(a,\mathfrak{T})=\frac{\sum\limits_{\substack{(x,y)\in\mathfrak{T}\\y=c}}\vec1\{a(x)=y\}}{\sum\limits_{\substack{(x,y)\in\mathfrak{T}\\y=c}}1},
\end{equation}
а для среднего качества решения задачи многоклассовой классификации
\begin{equation}
\label{eq:total_quality}
Q(a,\mathfrak{T})=\frac{1}{|\mathfrak{T}|}\sum\limits_{(x,y)\in\mathfrak{T}}\vec1\{a(x)=y\}.
\end{equation}
На диаграмме ниже приведено качество классификации, усредненное по~$m=50$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_WISDM_manual_features_nSplits_50_rate_0.7_approach_OneVsOne_HD_classifier_SVM_-t2-c8.5-g0.12}.eps}
\caption{Точность классификации при ручном выделении признаков.
Dataset:~WISDM.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:WISDM_manual_features}
\end{figure}

Как видно, классы~$3$~и~$4$ хорошо отделяются от остальных.
Таким образом, если сначала отделить эту пару классов от остальных, а потом настроить бинарный классификатор для разделения классов~$3$~и~$4$, вводя дополнительные признаки (например те, которые будут рассматриваются далее), можно добиться требуемого качества решения задачи, но это не входит в цели данного эксперимента.

\subsubsection{Модель авторегрессии~\ref{eq:autoregressive_model}}
\paragraph{Признаковое описание.}
\label{par:ar_feature_selection}
Во втором эксперименте в качестве признаковых описаний временных рядов использовались все статистические функции, что брались в первом эксперименте~\ref{par:manual_feature_selection}, за исключением гистограммы.
Вместо $10$ значений для каждого блока гистограммы использовались $7$ коэффициентов модели авторегрессии AR($6$)~(см.~\ref{eq:autoregressive_model}).
Так же, проводилась предварительная нормализация признаков.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-All и экспоненциальной функцией потерь.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=8,\ \gamma=0.8$.

\paragraph{Результаты.}
На диаграмме ниже приведено качество классификации, усредненное по~$m=50$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_WISDM_nSplits_50_rate_0.7_approach_OneVsAll_LLB_classifier_SVM_-t2-c8-g0.8}.eps}
\caption{Точность классификации для параметров модели авторегрессии в качестве признаковых описаний.
Dataset:~WISDM.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:WISDM_AR}
\end{figure}


\subsection{Датасет USC-HAD~\cite{mi12:ubicomp-sagaware}}
\label{seq:usc_had_dataset}
содержит показания акселерометра для 12 типов физической активности человека:
\begin{multicols}{2}
\begin{enumerate}
  \item walk forward
  \item walk left
  \item walk right
  \item go upstairs
  \item go downstairs
  \item run forward
  \item jump up and down
  \item sit and fidget
  \item stand
  \item sleep
  \item elevator up
  \item elevator down
\end{enumerate}
\end{multicols}

Выборка содержит примерно по $70$ шести"=компонентных временных ряда для каждого класса, а средняя длина временного ряда порядка~$3300$. Частота записи измерений сенсора~$100\,\text{Hz}$.

\subsubsection{Ручное выделение признаков}

\paragraph{Выбор признаков}
В качестве признаков брались те же признаки, что и в предыдущем эксперименте~\ref{par:manual_feature_selection}.

\paragraph{Классификатор}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-One.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=80,\ \gamma=0.002$.

\paragraph{Результаты}
Исходная выборка $100$ раз случайно разбивалась на обучающую и контрольную в отношении $7$ к $3$.
В таблице ниже приведен результат --- процент верной классификации для объектов каждого класса.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_USCHAD_manual_features_nSplits_100_rate_0.7_approach_OneVsOne_HD_classifier_SVM_-t2-c80-g0.002}.eps}
\caption{Точность классификации при ручном выделении признаков.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:USCHAD_manual_features}
\end{figure}


\subsubsection{Модель авторегрессии~\ref{eq:autoregressive_model}}

\paragraph{Признаковое описание.}
\label{par:ar_feature_selection_USCHAD}
При записи данных USC-HAD сенсор делал каждую секунду $100$~измерений.
Предполагая, что на каждое <<элементарное движение>> человек тратит порядка секунды, приходим к выводу, что параметры авторегрессионной модели малых порядков в данном случае неинформативны.
Приведем исходные временные ряды к частоте $10\,\text{Hz}$ при помощи осреднения.

В качестве признаковых описаний преобразованных временных рядов возьмем статистические функции из~\ref{par:manual_feature_selection}, за исключением гистограммы.
Так же для каждой компоненты отдельно и для модуля результирующего ускорения и поворота добавим по $11$~параметров авторегрессионной модели~AR($10$)~(см.~\ref{eq:autoregressive_model}).
Затем проведем нормализация признаков.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-All и экспоненциальной функцией потерь.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=16,\ \gamma=0.1$.

\paragraph{Результаты.}
На диаграмме ниже приведено качество классификации, усредненное по~$m=200$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_USCHAD_nSplits_200_rate_0.7_approach_OneVsAll_LLB_classifier_SVM_-t2-c16-g0.10}.eps}
\caption{Точность классификации для параметров модели авторегрессии в качестве признаковых описаний.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:USCHAD_AR}
\end{figure}

\subsubsection{Алгоритм голосования}
Будем решать задачу классификации только для первых $10$ классов (за исплючением <<elevator up>> и <<elevator down>>, которые плохо отделяются друг от друга и от класса <<stand>>) при помощи алгоритма голосования сегментов.

В качестве алгоритма сегментации используем разбиение исходного временного ряда на отрезки заданной длины.

Задача многоклассовой классификации решалась при помощи подхода One-vs-One с регуляризованной логистической регрессии (RLR) с параметром~$C=1$ в качестве бинарного классификатора.

На графике ниже приведены результаты для точности многоклассовой классификации, усредненные по $m=50$ случайным разбиениям.
\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{VotingSegments_Dataset_USCHAD_nSplits_50_rate_0.7_approach_OneVsOne_HD_classifier_SVMLinear_-c1}.eps}
\caption{Зависимость точности классификации от длины сегментов для алгоритма голосования.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.}
\label{fig:USCHAD_AR_VOTING}
\end{figure}

Из графика можно видеть, что алгоритм голосования позволил повысить точность классификации на~$1\%$.

% Для сравнения проведем два эксперимента.
% В первом эксперименте аргументом модели аппроксимации будет подаваться сам ряд~\ref{eq:equal_fragmenting}, во втором эксперименте будем разбивать ряд на сегменты~\ref{eq:segment_fragmenting}.
% В качестве сегментов будем брать подотрезки временного ряда длиной~$100$, не заботясь о периодах.

\subsection{Датасет MIT-BIH Arrhythmia Database~\cite{Goldberger13062000}}

% \begin{table}[t]
  % \caption{Качество многоклассовой классификации. Data~set:~MNIST, Binary~classifier:~Vote~SVM.}
  % \begin{tabular}{|l||l|l|l|l|l|l|l|l|l|l|l|l|}
    % \hline
    % & \multicolumn{12}{c|}{Подходы} \\ \cline{2-13}
    % Сжатие $\frac{d}{n}$ & \multicolumn{3}{c|}{One-vs-All} & \multicolumn{3}{c|}{One-vs-One} & \multicolumn{3}{c|}{ECOC-Random} & \multicolumn{3}{c|}{ECOC-BCH} \\ \cline{2-13}
    % & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$\\ \hline
% 0.05 & 76.6 					& 77.3 					& 78.2 					& 82.2 					& 83.3 					& 84.4 & 75.5 & 79.6 & 81.3 & 81.2 & 82.1 & 82.7\\ \hline
  % \end{tabular}
% \label{tbl:manual_usc_had}
% \end{table}

\bigskip
\section{Заключение}
Метод классификации временных рядов в пространстве распределений параметров порождающих моделей обобщает большинство других методов классификации временных рядов и позволяет производить более тонкую настройку алгоритма классификации.

% TODO: Вычислительный эксперимент показал (покажет?), что предложенный метод дает особенно хорошее качество классификации на квазипериодических рядах~(распознавание человеческой активности, данные ЭКГ) 

\bibliography{Karasikov2015TimeSeriesClassification}
\end{document}