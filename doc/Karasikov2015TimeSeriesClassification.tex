\documentclass[12pt,twoside]{article}

\usepackage{jmlda}
\usepackage{datetime}
\usepackage{multicol}
\graphicspath{{./pics/}}

\pgfplotsset{compat=1.12}

\bibliographystyle{gost780u}
\graphicspath{{./pics/}}


\begin{document}

%\NOREVIEWERNOTES
\title
    [Классификация временных рядов]
    {Классификация временных рядов в пространстве параметров порождающих моделей}
\author
    {Карасиков~М.\,Е.}
\email
    {karasikov@phystech.edu}
\organization
    {Московский физико-технический институт}
\thanks
    {Научный руководитель: Стрижов~В.\,В.}
\abstract
    {Работа посвящена задаче многоклассовой признаковой классификации временных рядов.
    Признаковая классификация временных рядов заключается в сопоставлении каждому временному ряду его краткого признакового описания, позволяющему решать задачу классификации в пространстве признаков.
    В работе исследуются методы построения пространства признаков временных рядов.
    При этом временной ряд рассматривается как последовательность сегментов, аппроксимируемых некоторой параметрической моделью, параметры которой используются в качестве их признаковых описаний.
    Построенное так признаковое описание сегмента временного ряда наследует от модели аппроксимации такие полезные свойства, как инвариантность относительно сдвига.
    Для решения задачи классификации в качестве признаковых описаний временных рядов предлагается использовать распределения параметров аппроксимирующих сегменты моделей, что обобщает базовые методы, использующие непосредственно сами параметры аппроксимирующих моделей.
    Проведен ряд вычислительных экспериментов на реальных данных, показавших высокое качество решения задачи многоклассовой классификации.
    Эксперименты показали превосходство предлагаемого метода над базовым и многими распространенными методами классификации временных рядов на всех рассмотренных наборах данных.

		\parindent=1cm \textbf{Последние изменения}: \currenttime, \today

		\bigskip
		\textbf{Ключевые слова}: \emph {временные ряды, многоклассовая классификация, сегментация временных рядов, гиперпараметры аппроксимирующей модели, модель авторегрессии, дискретное преобразование Фурье, дискретное вейвлет"=преобразование}.}
\titleEng
    {Time series feature"~based classification}
\authorEng
    {Karasikov~M.\,E.}
\organizationEng
    {Moscow Institute of Physics and Technology}
% \abstractEng
    % {We consider time series feature"~based classification problem.
    % Classification algorithm using model parameters distribution is proposed.
    % Empirical experiments on real data are conducted.

    % \bigskip
    % \textbf{Keywords}: \emph{time"~series, feature-based classification}.}

\maketitle
%\linenumbers

\section{Введение}
Временные ряды являются результатом проведения любых повторяющихся во времени измерений.
Обзор по методам и проблемам анализа временных рядов дается в~\cite{Esling:2012:TDM:2379776.2379788, fu2011review}.
Одними из основных методов анализа временных рядов являются
  прогнозирование~\cite{weigend1994time, brockwell2009time, tsay2005analysis},
  обнаружение аномалий~\cite{weiss2004mining, chin2005symbolic, yankov2008disk},
  сегментация~\cite{keogh2004segmenting, geurts2005segment, nunthanid2012parameter},
  кластеризация~\cite{Jain:1999:DCR:331499.331504, WarrenLiao20051857, zolhavarieh2014review}
  и классификация~\cite{bakshi1994representation, geurts2001pattern, wang2014human, Wei:2006:STS:1150402.1150498}.
Последние годы связаны с ростом интереса к данной области, проявляющимся в предложениях новых методов анализа временных рядов~---
  метрик~\cite{Ding:2008:QMT:1454159.1454226, keogh2004segmenting, berndt1994using, ratanamahatana2005novel, salvador2007toward, marteau2009time},
  алгоритмов сегментации~\cite{shatkay1996approximate, li1998malm, vasko2002estimating, palpanas2008streaming},
  кластеризации~\cite{frohwirth2008model, Corduas20081860, cormode2007conquering},
  и др.

Временным рядом~$x$ будем называть конечную упорядоченную последовательность:
\[
x = [x^{(1)}, \dots, x^{(t)}].
\]

В данной работе рассматривается задача классификации временных рядов, которая возникает во многих приложениях
  (медицинская диагностика по ЭКГ~\cite{PMID:8189152, keogh2006finding} и ЭЭГ~\cite{marcel2007person},
  классификация физической активности по данным с акселерометра~\cite{6889585, Kwapisz:2011:ARU:1964897.1964918},
  верификация динамических подписей~\cite{citeulike:3733947, gruber2006signature}~и~т.\,д.)
и заключается в определении неизвестных классов временных рядов рассматриваемого множества.

Формально задача классификации в общем виде может быть поставлена следующим образом.
Пусть~$X$~--- множество описаний объектов произвольной природы,
$Y$~--- конечное множество меток классов.
Предполагается существование целевой функции~--- отображения~$y: X\to Y$,
значения которого известны только на~объектах обучающей выборки
\[
		\mathfrak{D} = \left\{(x_1,y_1),\dots,(x_m,y_m)\right\} \subset X\times Y.
\]
Требуется построить алгоритм~$a: X\to Y$~--- отображение,
приближающее целевую функцию~$y$ на~множестве~$X$.
Задачей классификации временных рядов будем называть задачу классификации, в которой объектами классификации являются временные ряды.

Этап построения информативного пространства признаков, позволяющего добиться заданной точности классификации, является одним из важнейших этапов решения задачи классификации.

Одним из способов построения пространства признаков в задаче классификации временных рядов является задание функции расстояния~\cite{Ding:2008:QMT:1454159.1454226, keogh2004segmenting, berndt1994using, ratanamahatana2005novel, salvador2007toward, marteau2009time} между временными рядами, позволяющего в качестве признаков взять расстояния до опорных объектов.
Данный метод чрезвычайно распространен в силу того, что позволяет свести исходную задачу классификации временных рядов к задаче выбора метрики~--- функции расстояния.
При удачном выборе метрики дальнейшая классификация может происходить при помощи простейших метрических алгоритмов классификации, например, методом ближайшего соседа~\cite{Spiegel:2011:PRC:2003653.2003657}.
Данный подход так же зарекомендовал себя в self"~training~\cite{Wei:2006:STS:1150402.1150498} и graph"~based~\cite{nguyen2011positive, marussy2013success} методах частичного обучения.

Другой способ состоит в извлечении из каждого временного ряда набора признаков~--- его информативного описания, позволяющего строить точные классификаторы с хорошей обобщающей способностью.
В качестве признаков могут браться буквально произвольные функции~$\vec{f}:X\rightarrow\mathbb{R}^n$ исходных объектов.
Например, признаки могут задаваться экспертом.
Так в работе~\cite{Nanopoulos01feature-basedclassification} предлагается использовать в качестве признаков статистические функции (среднее, отклонения от среднего, коэффициенты эксцесса и др.).
Стоит заметить, что при таком подходе к построению пространства признаков часто удается добиться необходимого качества классификации путем выбора соответствующих конкретной задаче признаков (см. пример ~\cite{wiens2012patient}).
Второй метод построения пространства признаков заключается в задании параметрической регрессионной или аппроксимирующей модели временного ряда.
Таким образом, в качестве признаков временных рядов будут выступать параметры заданной модели.
При этом возникает задача выбора модели для описания временного ряда~\cite{}.
Так в работе~\cite{morchen2003time} в качестве признаков предлагается использовать коэффициенты дискретного преобразования Фурье (DFT).
В~\cite{morchen2003time, zhang2004non} предлагается использовать дискретное вейвлет"=преобразование (DWT), которое сравнивается с предыдущими методами.
Особенно эффективно DFT и DWT работают на квазипериодических рядах, где проявляется периодическая структура.

Метод извлечения признаков на основе регрессионных моделей является общим и может быть использован при работе с произвольными объектами.
Однако, временные ряды всегда являются некоторыми конечными последовательностями, из которых можно выделять фрагменты~--- некоторые подпоследовательности.
Каждый из фрагментов тоже является временным рядом, а, следовательно, для для него тоже может быть получено признаковое описание.
Таким образом, каждый временной ряд может быть описан распределением признаков его фрагментов.
Заметим, что формально данный подход является обобщением выше изложенного, в котором из ряда выделяется единственный фрагмент~--- сам ряд, а функции распределения признаков вырождены.

В частном случае, когда временной ряд является квазипериодическим, существует возможность выделения в нем характерных сегментов~--- периодов, то есть возможность представления каждого временного ряда~$x = [x^{(1)}, \dots, x^{(t)}]$ последовательностью в определенном смысле похожих его сегментов~$s^{(1)},\dots,s^{(p)}:$
\[
s^{(1)}=[x^{(1)}, \dots, x^{(t_1)}],
\ \dots\ ,
s^{(k)}=[x^{(t_{k-1} + 1)}, \dots, x^{(t_k)}],
\ \dots\ ,
s^{(p)}=[x^{(t_{p-1} + 1)},\dots,x^{(t)}].
\]
В таком случае будем писать
\begin{equation}
\label{eq:periodic}
x=(s^{(1)}, \dots, s^{(p)}).
\end{equation}
Для выделения периодов могут быть использованы, например, алгоритмы~\cite{keogh2004segmenting, geurts2005segment, nunthanid2012parameter, shatkay1996approximate, li1998malm, vasko2002estimating, palpanas2008streaming}.

В нашей работе предлагается алгоритм классификации квазипериодических временных рядов на основе распределения параметров модели, описывающей сегменты временных рядов.
Предлагаемый подход к классификации квазипериодических временных рядов в общем виде изложен в разделе~\ref{sec:problem_statement}.
В разделе~\ref{sec:computational_experiment} представлены эксперименты на реальных данных по сравнению предложенного подхода с подходом, предложенным в~\cite{6889585}.

\bigskip
\section{Постановка задачи}
\label{sec:problem_statement}
Поставим задачу в общем виде.

Пусть $(X,d)$~--- метрическое пространство временных рядов, $Y$~--- множество меток классов.
Дано конечное множество временных рядов~$X^\ell=\{x_1,\dots,x_\ell\}\subset X$ и обучающая выборка~$\mathfrak{D}\subset X^\ell\times Y$.

 % состоящих из сегментов~--- элементов некоторого метрического пространства~$(S,d)$:
% \[
% x_i=(s^{(1)}_i,\dots,s^{(p)}_i)\in S^p,\quad i=1,\dots,\ell;
% \]

Заданы алгоритм выделения фрагментов временного ряда
\begin{equation}
\label{eq:fragmenting}
s:\;x\mapsto (s^{(1)},\dots,s^{(p)})\in X^p,\text{ где } p=p(x),
\end{equation}
и параметрическая регрессионная модель фрагментов временного ряда
\begin{equation}
\label{eq:regression}
g:\;\mathbb{R}^n\times X\rightarrow X.
\end{equation}
Каждому фрагменту~$s^{(k)}$ временного ряда~$x$ поставим в соответствие его вектор признаков
\begin{equation}
\label{eq:feature_solution}
\vec{f}(s^{(k)}) =
\argmin_{\vec{w}\in \mathbb{R}^n} d\left(g(\vec{w},s^{(k)}), s^{(k)}\right).
\end{equation}
Таким образом, каждому временному ряду~$x$ соответствует набор векторов признаков
\[
\mathbf{f}=\left(\vec{f}(s^{(1)}),\dots,\vec{f}(s^{(p)})\right)
\]
его фрагментов.

% Пусть~$F(\vec{x})$~--- функция распределения, восстановленная по выборке~$F_i$.

Задано некоторое семейство алгоритмов классификации
\begin{equation}
\label{eq:classifiers}
A=\{a:\;\mathbf{f}\mapsto y\in Y\}
\end{equation}
и функция потерь
\[
\mathscr{L}:\;X\times Y\rightarrow \mathbb{R}.
\]

Найти алгоритм классификации~$a^*\in A,$ доставляющий минимум функционалу качества~$Q(a, \mathfrak{D})\in \mathbb{R},\quad a\in A:$
\begin{align*}
a^*
& = \argmin_{a\in A}Q(a,\mathfrak{D})=\\
& = \argmin_{a\in A}\frac{1}{|\mathfrak{D}|}\sum\limits_{(x_i,y_i)\in\mathfrak{D}}      \mathscr{L}\left(a\left(\mathbf{f}_i\right),y_i\right).
\end{align*}

\bigskip
\section{Выделение фрагментов}
В данном разделе рассматривается проблема выделения фрагментов из временного ряда~(см.~\ref{eq:fragmenting}).
Фрагментом временного ряда~$x=[x^{(1)},\dots,x^{(t)}]$ будем называть любую его подпоследовательность~$s=[x^{(i_1)},\dots,x^{(i_k)}],$ где $1\leq i_1\leq\dots\leq i_k\leq t$.
Например, сам временной ряд~$x$ является своим фрагментом.
То есть в качестве алгоритма выделения временного ряда можно взять
\begin{equation}
\label{eq:equal_fragmenting}
s:\;x\mapsto x\in X.
\end{equation}

Пусть теперь временной ряд является квазипериодическим.
То есть справедливо представление~\ref{eq:periodic}.
Тогда возьмем в качестве фрагментов ряда его сегменты
\begin{equation}
\label{eq:segment_fragmenting}
s:\;x\mapsto (s^{(1)},\dots,s^{(p)})\in X^p.
\end{equation}
Сегментация временных рядов может проводиться согласно алгоритмам~\cite{keogh2004segmenting, geurts2005segment, nunthanid2012parameter, shatkay1996approximate, li1998malm, vasko2002estimating, palpanas2008streaming}.
Общие требования к процедуре выделения фрагментов из временных рядов сформулированы в разделе~\ref{sec:classification}.

\bigskip
\section{Регрессионная модель временного ряда}
\label{sec:regression_model}
В качестве признаков фрагментов временного ряда используется вектор параметров аппроксимирующей модели~\ref{eq:regression}.
Рассмотрим несколько простых примеров.
\begin{itemize}
\item \textbf{Простая линейная регрессия}.
Пусть задан многокомпонентный временной ряд~(например, время и 3 пространственные координаты):
\[
x = [\vec{x}^{(1)}, \dots, \vec{x}^{(t)}],\quad
\text{где}\quad
\vec{x}^{(k)}=[z_0^{(k)},\dots,z_r^{(k)}]\T.
\]
Тогда нашей аппроксимирующей моделью, например, может быть модель линейной регрессии одной из компонент временного ряда на остальные компоненты:
\[
g(\vec{w},x)=[\hat{\vec{x}}^{(1)},\dots,\hat{\vec{x}}^{(t)}],\quad\text{где}\quad
\hat{\vec{x}}^{(k)}=[\hat{z}_0^{(k)},z_1^{(k)},\dots,z_r^{(k)}]\T,\ k=1,\dots,t,
\]
\[
\hat{\vec{z}}_0=
\begin{bmatrix}
\hat{z}_0^{(1)} \\
\vdots  \\
\hat{z}_0^{(t)}
\end{bmatrix}=
\begin{bmatrix}
\hat{z}_1^{(1)} & \dots & \hat{z}_r^{(1)} \\
\vdots         & \ddots & \vdots          \\
\hat{z}_1^{(t)} & \dots & \hat{z}_r^{(t)}
\end{bmatrix}
\begin{bmatrix}
w_1 \\
\vdots  \\
w_r
\end{bmatrix}.
\]

\item \textbf{Авторегрессионная модель AR($k$)}.
Задан временной ряд
\[
x = [x^{(1)},\dots,x^{(t)}],\quad x^{(k)}\in\mathbb{R}.
\]
Выберем в качестве модели порождения авторегрессионную модель порядка~$p$:
\begin{equation}
\label{eq:autoregressive_model}
g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
\hat{x}^{(k)}=w_0 + \sum\limits_{i=1}^{p} w_i x^{k-i},\ k=1,\dots,t.
\end{equation}

\item \textbf{Дискретное преобразование Фурье}.
Задан временной ряд
\[
x = [x^{(0)},\dots,x^{(t-1)}],\quad x^{(k)}\in\mathbb{R}.
\]
Очевидно, что задание признакового описания временного ряда коэффициентами Фурье эквивалентно заданию порождающей модели
\[
g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
\hat{x}^{(k)}=\frac{1}{t}\sum\limits_{j=0}^{t-1} w_j e^{\frac{2\pi i}{t}kj},\ k=0,\dots,t-1
\]
и евклидового расстояния в пространстве временных рядов.

% Запишем преобразование Фурье
% \[
% w_k = \sum\limits_{j=0}^{t-1} x^{(j)}e^{-\frac{2\pi i}{t}kj},\ k=0,\dots,t-1.
% \]
% и занулим все коэффициенты кроме первых~$p$:
% \[
% g(\vec{w},x)=[\hat{x}^{(1)},\dots,\hat{x}^{(t)}],\quad\text{где}\quad
% \hat{x}^{(k)}=w_0 + \sum\limits_{i=1}^{p} w_i x^{k-i},\ k=1,\dots,t.
% \]
\end{itemize}
Приведенные примеры демонстрируют большую общность построения пространства признаков при помощи модели типа~\ref{eq:regression} и решения оптимизационной задачи~\ref{eq:feature_solution}.
Вообще, легко видеть, что любая функция временного ряда~$\vec{f}:X\rightarrow \mathbb{R}^n$ может быть задана как решение оптимизационной задачи~\ref{eq:feature_solution} с соответствующей моделью~\ref{eq:regression} и функцией расстояния~$d$.

\bigskip
\section{Алгоритм классификации}
\label{sec:classification}
В данном разделе займемся задачей построения семейства алгоритмов~\ref{eq:classifiers}.
Пусть
\[
\mathbf{f}_i=\left(\vec{f}_i^{(1)},\dots,\vec{f}_i^{(p)}\right)
\]
--- полученное признаковое описание временного ряда~$x_i\in X^\ell$, где~$\vec{f}_i^{(k)}$~--- вектор признаков $k$"~го фрагмента этого ряда.
Признаковое описание~$\mathbf{f}_i$ можно рассматривать как реализацию выборки случайных величин
\[
\mathbf{F}_i=\left(\vec{F}_i^{(1)},\dots,\vec{F}_i^{(p)}\right).
\]
Примем гипотезу о простоте выборок~$\mathbf{F}_i,\ i=1,\dots,\ell.$
Данная гипотеза формулирует требования на метод фрагментации~\ref{eq:fragmenting}.
Тогда временной ряд естественно описывать распределением параметров порождающей модели его сегментов.
Пусть задана некоторая параметрическое семейство распределений~$\left\{\mathsf{P}_\theta\right\}_{\theta\in \Theta}$.
Тогда, получив оценку максимального правдоподобия
\[
\theta_i=\argmax_{\theta\in\Theta}L(\theta\,|\,\mathbf{f}_i),
\]
будем считать её признаковым описанием исходного временного ряда.
Таким образом, задача классификации временных рядов свелась к задаче классификации параметров распределений из семейства~$\left\{\mathsf{P}_\theta\right\}_{\theta\in \Theta}$.
При этом, имея априорное распределение параметра~$G(v)=\mathsf{P}\{\theta<v\}$, целесообразно использовать вместо оценки максимального правдоподобия апостериорное математическое ожидание параметра
\[
\theta_i=\mathsf{E}\left[\theta\,|\,\mathbf{f}_i\right].
\]

\bigskip
\section{Вычислительный эксперимент}
\label{sec:computational_experiment}

Вычислительный эксперимент проводился на данных для задачи классификации типов физической активности человека.

\subsection{Датасет WISDM~\cite{Kwapisz:2011:ARU:1964897.1964918}}
содержит показания акселерометра для $6$~видов человеческой активности:
\begin{multicols}{2}
\begin{enumerate}
  \item Jogging
  \item Walking
  \item Upstairs
  \item Downstairs
  \item Sitting
  \item Standing
\end{enumerate}
\end{multicols}

Необработанные временные ряды, представляющие из себя последовательность размеченных показаний акселерометра (по тройке чисел на каждый отсчет времени с интервалом в $50$ миллисекунд), были разбиты на временные ряды длиной по $200$~отсчетов~($10$~секунд).

\begin{table}[H]
  \begin{tabular}{|c||c|c|c|c|c|c|}
    \hline
    Классы & Jogging & Walking & Upstairs & Downstairs & Sitting & Standing\\ \hline
    Число объектов & $1624$ & $2087$ & $549$ & $438$ & $276$ & $231$\\ \hline
  \end{tabular}
  \caption{Распределение временных рядов по классам. Dataset:~WISDM.}
\label{tbl:manual_usc_had}
\end{table}

\subsubsection{Ручное выделение признаков}
\paragraph{Выбор признаков.}
\label{par:manual_feature_selection}
В первом эксперименте в качестве признаковых описаний временных рядов использовались их статистические функции.
Каждой компоненте временного ряда сопоставлялись $40$~чисел~--- её среднее, стандартное отклонение, средний модуль отклонения от среднего, гистограмма с $10$ областями равной ширины.
Полученные признаки для каждой компоненты объединялись и к ним добавлялся признак средней величины ускорения.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-One.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=8.5,\ \gamma=0.12$.

\paragraph{Результаты.}
Для оценки качества решения использовалась процедура скользящего контроля.
Исходная обучающая выборка~$\mathfrak{D}$ случайно разбивается $m$ раз на обучающую и контрольную~($\mathfrak{D}=\mathfrak{L_i}\sqcup\mathfrak{T_i}$). В качестве внешнего критерия качества метода обучения~$\mu$ бралось
\[
\frac{1}{m}\sum_{i=1}^{m}Q(\mu(\mathfrak{L_i}),\mathfrak{T_i}),
\]
где для средней точности (accuracy) классификации объектов класса~$c\in Y$
\begin{equation}
\label{eq:class_quality}
Q_c(a,\mathfrak{T})=\frac{\sum\limits_{\substack{(x,y)\in\mathfrak{T}\\y=c}}\vec1\{a(x)=y\}}{\sum\limits_{\substack{(x,y)\in\mathfrak{T}\\y=c}}1},
\end{equation}
а для среднего качества решения задачи многоклассовой классификации
\begin{equation}
\label{eq:total_quality}
Q(a,\mathfrak{T})=\frac{1}{|\mathfrak{T}|}\sum\limits_{(x,y)\in\mathfrak{T}}\vec1\{a(x)=y\}.
\end{equation}
На диаграмме ниже приведено качество классификации, усредненное по~$m=50$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_WISDM_manual_features_nSplits_50_rate_0.7_approach_OneVsOne_HD_classifier_SVM_-t2-c8.5-g0.12}.eps}
\caption{Точность классификации при ручном выделении признаков.
Dataset:~WISDM.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:WISDM_manual_features}
\end{figure}

Как видно, классы~$3$~и~$4$ хорошо отделяются от остальных.
Таким образом, если сначала отделить эту пару классов от остальных, а потом настроить бинарный классификатор для разделения классов~$3$~и~$4$, вводя дополнительные признаки (например те, которые будут рассматриваются далее), можно добиться требуемого качества решения задачи, но это не входит в цели данного эксперимента.

\subsubsection{Модель авторегрессии~\ref{eq:autoregressive_model}}
\paragraph{Признаковое описание.}
\label{par:ar_feature_selection}
Во втором эксперименте в качестве признаковых описаний временных рядов использовались все статистические функции, что брались в первом эксперименте~\ref{par:manual_feature_selection}, за исключением гистограммы.
Вместо $10$ значений для каждого блока гистограммы использовались $7$ коэффициентов модели авторегрессии AR($6$)~(см.~\ref{eq:autoregressive_model}).
Так же, проводилась предварительная нормализация признаков.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-All и экспоненциальной функцией потерь.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=8,\ \gamma=0.8$.

\paragraph{Результаты.}
На диаграмме ниже приведено качество классификации, усредненное по~$m=50$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_WISDM_nSplits_50_rate_0.7_approach_OneVsAll_LLB_classifier_SVM_-t2-c8-g0.8}.eps}
\caption{Точность классификации для параметров модели авторегрессии в качестве признаковых описаний.
Dataset:~WISDM.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:WISDM_AR}
\end{figure}


\subsection{Датасет USC-HAD~\cite{mi12:ubicomp-sagaware}}
\label{seq:usc_had_dataset}
содержит показания акселерометра для 12 типов физической активности человека:
\begin{multicols}{2}
\begin{enumerate}
  \item walk forward
  \item walk left
  \item walk right
  \item go upstairs
  \item go downstairs
  \item run forward
  \item jump up and down
  \item sit and fidget
  \item stand
  \item sleep
  \item elevator up
  \item elevator down
\end{enumerate}
\end{multicols}

Выборка содержит примерно по $70$ шести"=компонентных временных ряда для каждого класса, а средняя длина временного ряда порядка~$3300$. Частота записи измерений сенсора~$100\,\text{Hz}$.

\subsubsection{Ручное выделение признаков}

\paragraph{Выбор признаков}
В качестве признаков брались те же признаки, что и в предыдущем эксперименте~\ref{par:manual_feature_selection}.

\paragraph{Классификатор}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-One.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=80,\ \gamma=0.002$.

\paragraph{Результаты}
Исходная выборка $100$ раз случайно разбивалась на обучающую и контрольную в отношении $7$ к $3$.
В таблице ниже приведен результат --- процент верной классификации для объектов каждого класса.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_USCHAD_manual_features_nSplits_100_rate_0.7_approach_OneVsOne_HD_classifier_SVM_-t2-c80-g0.002}.eps}
\caption{Точность классификации при ручном выделении признаков.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:USCHAD_manual_features}
\end{figure}


\subsubsection{Модель авторегрессии~\ref{eq:autoregressive_model}}

\paragraph{Признаковое описание.}
\label{par:ar_feature_selection_USCHAD}
При записи данных USC-HAD сенсор делал каждую секунду $100$~измерений.
Предполагая, что на каждое <<элементарное движение>> человек тратит порядка секунды, приходим к выводу, что параметры авторегрессионной модели малых порядков в данном случае неинформативны.
Приведем исходные временные ряды к частоте $10\,\text{Hz}$ при помощи осреднения.

В качестве признаковых описаний преобразованных временных рядов возьмем статистические функции из~\ref{par:manual_feature_selection}, за исключением гистограммы.
Так же для каждой компоненты отдельно и для модуля результирующего ускорения и поворота добавим по $11$~параметров авторегрессионной модели~AR($10$)~(см.~\ref{eq:autoregressive_model}).
Затем проведем нормализация признаков.

\paragraph{Классификатор.}
Задача многоклассовой классификации сводилась к задаче бинарной классификации при помощи подхода One-vs-All и экспоненциальной функцией потерь.
В качестве бинарного классификатора использовался SVM с гауссовским ядром и параметрами $C=16,\ \gamma=0.1$.

\paragraph{Результаты.}
На диаграмме ниже приведено качество классификации, усредненное по~$m=200$ случайным разбиениям исходной выборки на тестовую и контрольную в отношении $7$ к $3$.

\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{Accuracy_Dataset_USCHAD_nSplits_200_rate_0.7_approach_OneVsAll_LLB_classifier_SVM_-t2-c16-g0.10}.eps}
\caption{Точность классификации для параметров модели авторегрессии в качестве признаковых описаний.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.
Над столбцами приведены средние точности классификации для каждого класса по формуле~\ref{eq:class_quality}.}
\label{fig:USCHAD_AR}
\end{figure}

\subsubsection{Алгоритм голосования}
Будем решать задачу классификации только для первых $10$ классов (за исплючением <<elevator up>> и <<elevator down>>, которые плохо отделяются друг от друга и от класса <<stand>>) при помощи алгоритма голосования сегментов.

В качестве алгоритма сегментации используем разбиение исходного временного ряда на отрезки заданной длины.

Задача многоклассовой классификации решалась при помощи подхода One-vs-One с регуляризованной логистической регрессии (RLR) с параметром~$C=1$ в качестве бинарного классификатора.

На графике ниже приведены результаты для точности многоклассовой классификации, усредненные по $m=50$ случайным разбиениям.
\begin{figure}[H]
\includegraphics[width=0.5\textwidth]{{VotingSegments_Dataset_USCHAD_nSplits_50_rate_0.7_approach_OneVsOne_HD_classifier_SVMLinear_-c1}.eps}
\caption{Зависимость точности классификации от длины сегментов для алгоритма голосования.
Dataset:~USC-HAD.
Под Mean accuracy понимается значение функционала~\ref{eq:total_quality}.}
\label{fig:USCHAD_AR_VOTING}
\end{figure}

Из графика можно видеть, что алгоритм голосования позволил повысить точность классификации на~$1\%$.

% Для сравнения проведем два эксперимента.
% В первом эксперименте аргументом модели аппроксимации будет подаваться сам ряд~\ref{eq:equal_fragmenting}, во втором эксперименте будем разбивать ряд на сегменты~\ref{eq:segment_fragmenting}.
% В качестве сегментов будем брать подотрезки временного ряда длиной~$100$, не заботясь о периодах.

\subsection{Датасет MIT-BIH Arrhythmia Database~\cite{Goldberger13062000}}

% \begin{table}[t]
  % \caption{Качество многоклассовой классификации. Data~set:~MNIST, Binary~classifier:~Vote~SVM.}
  % \begin{tabular}{|l||l|l|l|l|l|l|l|l|l|l|l|l|}
    % \hline
    % & \multicolumn{12}{c|}{Подходы} \\ \cline{2-13}
    % Сжатие $\frac{d}{n}$ & \multicolumn{3}{c|}{One-vs-All} & \multicolumn{3}{c|}{One-vs-One} & \multicolumn{3}{c|}{ECOC-Random} & \multicolumn{3}{c|}{ECOC-BCH} \\ \cline{2-13}
    % & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$ & $min$ & $avg$ & $max$\\ \hline
% 0.05 & 76.6 					& 77.3 					& 78.2 					& 82.2 					& 83.3 					& 84.4 & 75.5 & 79.6 & 81.3 & 81.2 & 82.1 & 82.7\\ \hline
  % \end{tabular}
% \label{tbl:manual_usc_had}
% \end{table}

\bigskip
\section{Заключение}
Метод классификации временных рядов в пространстве распределений параметров порождающих моделей обобщает большинство других методов классификации временных рядов и позволяет производить более тонкую настройку алгоритма классификации.

% TODO: Вычислительный эксперимент показал (покажет?), что предложенный метод дает особенно хорошее качество классификации на квазипериодических рядах~(распознавание человеческой активности, данные ЭКГ) 

\bibliography{Karasikov2015TimeSeriesClassification}
\end{document}